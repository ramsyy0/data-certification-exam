{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Popularity Predictor (39%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this challenge is to create a model that predicts the popularity of a song based on its features.\n",
    "\n",
    "The dataset contains a list of tracks with the following characteristics:\n",
    "- `acousticness`: whether the track is acoustic\n",
    "- `danceability`: describes how suitable a track is for dancing\n",
    "- `duration_ms`: duration of the track in milliseconds\n",
    "- `energy`: represents a perceptual measure of intensity and activity\n",
    "- `explicit`: whether the track has explicit lyrics\n",
    "- `id`: id for the track\n",
    "- `instrumentalness`: predicts whether a track contains no vocals\n",
    "- `key`: the key the track is in\n",
    "- `liveness`: detects the presence of an audience in the recording\n",
    "- `loudness`: the overall loudness of a track in decibels\n",
    "- `mode`: modality of a track\n",
    "- `name`: name of the track\n",
    "- `popularity`: popularity of the track\n",
    "- `release_date`: release date\n",
    "- `speechiness`: detects the presence of spoken words in a track\n",
    "- `tempo`: overall estimated tempo of a track in beats per minute\n",
    "- `valence`: describes the musical positiveness conveyed by a track\n",
    "- `artist`: artist who performed the track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection\n",
    "\n",
    "**üìù Load the `spotify_popularity_train.csv` dataset from the provided URL. Display the first few rows. Perform the usual cleaning operations. Store the result in a `DataFrame` named `data`.**\n",
    "\n",
    "üëâ Do not forget to clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://wagon-public-datasets.s3.amazonaws.com/certification_paris_2021Q1/spotify_popularity_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>id</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.65400</td>\n",
       "      <td>0.499</td>\n",
       "      <td>219827</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0</td>\n",
       "      <td>0B6BeEUd6UwFlbsHMQKjob</td>\n",
       "      <td>0.00409</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>-16.435</td>\n",
       "      <td>1</td>\n",
       "      <td>Back in the Goodle Days</td>\n",
       "      <td>40</td>\n",
       "      <td>1971</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>149.460</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>John Hartford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00592</td>\n",
       "      <td>0.439</td>\n",
       "      <td>483948</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0</td>\n",
       "      <td>5Gpx4lJy3vKmIvjwbiR5c8</td>\n",
       "      <td>0.14000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>-8.497</td>\n",
       "      <td>1</td>\n",
       "      <td>Worlds Which Break Us - Intro Mix</td>\n",
       "      <td>22</td>\n",
       "      <td>2015-02-02</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>138.040</td>\n",
       "      <td>0.0587</td>\n",
       "      <td>Driftmoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.73400</td>\n",
       "      <td>0.523</td>\n",
       "      <td>245693</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0</td>\n",
       "      <td>7MxuUYqrCIy93h1EEHrIrL</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>-11.506</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm The Greatest Star</td>\n",
       "      <td>40</td>\n",
       "      <td>1968-09-01</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>75.869</td>\n",
       "      <td>0.4640</td>\n",
       "      <td>Barbra Streisand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms  energy  explicit  \\\n",
       "0       0.65400         0.499       219827   0.190         0   \n",
       "1       0.00592         0.439       483948   0.808         0   \n",
       "2       0.73400         0.523       245693   0.288         0   \n",
       "\n",
       "                       id  instrumentalness  key  liveness  loudness  mode  \\\n",
       "0  0B6BeEUd6UwFlbsHMQKjob           0.00409    7    0.0898   -16.435     1   \n",
       "1  5Gpx4lJy3vKmIvjwbiR5c8           0.14000    2    0.0890    -8.497     1   \n",
       "2  7MxuUYqrCIy93h1EEHrIrL           0.00000    0    0.0771   -11.506     1   \n",
       "\n",
       "                                name  popularity release_date  speechiness  \\\n",
       "0            Back in the Goodle Days          40         1971       0.0454   \n",
       "1  Worlds Which Break Us - Intro Mix          22   2015-02-02       0.0677   \n",
       "2              I'm The Greatest Star          40   1968-09-01       0.2140   \n",
       "\n",
       "     tempo  valence            artist  \n",
       "0  149.460   0.4300     John Hartford  \n",
       "1  138.040   0.0587         Driftmoon  \n",
       "2   75.869   0.4640  Barbra Streisand  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(url)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52317 entries, 0 to 52316\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   acousticness      52317 non-null  float64\n",
      " 1   danceability      52317 non-null  float64\n",
      " 2   duration_ms       52317 non-null  int64  \n",
      " 3   energy            52317 non-null  float64\n",
      " 4   explicit          52317 non-null  int64  \n",
      " 5   id                52317 non-null  object \n",
      " 6   instrumentalness  52317 non-null  float64\n",
      " 7   key               52317 non-null  int64  \n",
      " 8   liveness          52317 non-null  float64\n",
      " 9   loudness          52317 non-null  float64\n",
      " 10  mode              52317 non-null  int64  \n",
      " 11  name              52317 non-null  object \n",
      " 12  popularity        52317 non-null  int64  \n",
      " 13  release_date      52317 non-null  object \n",
      " 14  speechiness       52317 non-null  float64\n",
      " 15  tempo             52317 non-null  float64\n",
      " 16  valence           52317 non-null  float64\n",
      " 17  artist            52313 non-null  object \n",
      "dtypes: float64(9), int64(5), object(4)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates, drop null values\n",
    "data = data.drop_duplicates().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale values\n",
    "scaler = MinMaxScaler()\n",
    "features_to_scale = ['acousticness', \n",
    "                   'danceability', \n",
    "                   'duration_ms',\n",
    "                   'energy', \n",
    "                   'explicit', \n",
    "                   'instrumentalness', \n",
    "                   'liveness', \n",
    "                   'loudness',\n",
    "                   'mode',\n",
    "                   'speechiness',\n",
    "                   'tempo',\n",
    "                   'valence'\n",
    "                  ]\n",
    "data[features_to_scale] = scaler.fit_transform(data[features_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your results\n",
    "\n",
    "Run the following cell to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "ChallengeResult(\n",
    "    \"c5_data_cleaning\",\n",
    "    data=data).write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù We want to use a metric that measures the prediction error in the same unit than `popularity`. In addition, it should strongly penalize largest errors. Which sklearn's [metric](https://scikit-learn.org/stable/modules/model_evaluation.html) should we use? Store its exact name as string below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = \"neg_mean_squared_error\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Let's build a baseline model using only the numerical features in our dataset.**\n",
    "- Build `X_baseline` with only numerical features\n",
    "- Build `y` your target containing the `popularity`\n",
    "- Then 5 times cross validate the baseline linear model of your choice (do not fine tune it)\n",
    "- Store your mean performance in a `float` variable named `baseline_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_baseline = data[['acousticness', \n",
    "                   'danceability', \n",
    "                   'duration_ms', \n",
    "                   'energy', \n",
    "                   'explicit', \n",
    "                   'instrumentalness', \n",
    "                   'liveness', \n",
    "                   'loudness',\n",
    "                   'mode',\n",
    "                   'speechiness',\n",
    "                   'tempo',\n",
    "                   'valence'\n",
    "                  ]]\n",
    "\n",
    "y = data['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = DummyRegressor(strategy=\"median\")\n",
    "cv_results = cross_validate(baseline_model, X_baseline, y, cv=5, scoring=scoring)\n",
    "baseline_score = cv_results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your results\n",
    "\n",
    "Run the following cell to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "ChallengeResult(\n",
    "    \"baseline\",\n",
    "    scoring=scoring,\n",
    "    baseline_score=baseline_score).write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "Let's now use the features that we left aside: `release_date` and `artist` to improve the performance of our model. We'll create them manually in a train vs. test context first (and pipeline them later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### holdout\n",
    "**üìù Create the 4 variables `X_train` `y_train`, `X_test`, `y_test` with a 50% split with random sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['acousticness', \n",
    "           'danceability', \n",
    "           'duration_ms', \n",
    "           'energy', \n",
    "           'explicit', \n",
    "           'instrumentalness', \n",
    "           'liveness', \n",
    "           'loudness',\n",
    "           'mode',\n",
    "           'speechiness',\n",
    "           'tempo',\n",
    "           'valence',\n",
    "           'release_date',\n",
    "           'artist',\n",
    "          ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### year\n",
    "\n",
    "**üìù Create `X_train_year` and `X_test_year` by adding the new column `year` containing the release year of the track as integer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_year = X_train.copy()\n",
    "X_train_year['year'] = pd.to_datetime(X_train_year['release_date']).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_year = X_test.copy()\n",
    "X_test_year['year'] = pd.to_datetime(X_test_year['release_date']).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>release_date</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27694</th>\n",
       "      <td>0.996988</td>\n",
       "      <td>0.639959</td>\n",
       "      <td>0.025517</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.086486</td>\n",
       "      <td>0.608198</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>0.346581</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>Donald Shoenberg</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50854</th>\n",
       "      <td>0.692771</td>\n",
       "      <td>0.717039</td>\n",
       "      <td>0.060294</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.100100</td>\n",
       "      <td>0.746784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025876</td>\n",
       "      <td>0.349452</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>1985</td>\n",
       "      <td>Eagles</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11557</th>\n",
       "      <td>0.888554</td>\n",
       "      <td>0.184584</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.656657</td>\n",
       "      <td>0.538702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.039278</td>\n",
       "      <td>0.446969</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>1948</td>\n",
       "      <td>Igor Stravinsky</td>\n",
       "      <td>1948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42812</th>\n",
       "      <td>0.950803</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.028197</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.090691</td>\n",
       "      <td>0.725260</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.037526</td>\n",
       "      <td>0.422592</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>2014</td>\n",
       "      <td>William Elliott Whitmore</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26106</th>\n",
       "      <td>0.668675</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.062163</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.359359</td>\n",
       "      <td>0.840252</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.057629</td>\n",
       "      <td>0.549159</td>\n",
       "      <td>0.1780</td>\n",
       "      <td>2013-11-07</td>\n",
       "      <td>‡πÄ‡∏ö‡∏ô‡∏ã‡πå-‡∏û‡∏£‡∏¥‡∏Å‡πÑ‡∏ó‡∏¢</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acousticness  danceability  duration_ms  energy  explicit  \\\n",
       "27694      0.996988      0.639959     0.025517  0.0346       0.0   \n",
       "50854      0.692771      0.717039     0.060294  0.3460       0.0   \n",
       "11557      0.888554      0.184584     0.013900  0.0331       0.0   \n",
       "42812      0.950803      0.235294     0.028197  0.0303       0.0   \n",
       "26106      0.668675      0.637931     0.062163  0.5050       0.0   \n",
       "\n",
       "       instrumentalness  liveness  loudness  mode  speechiness     tempo  \\\n",
       "27694             0.959  0.086486  0.608198   1.0     0.051753  0.346581   \n",
       "50854             0.145  0.100100  0.746784   0.0     0.025876  0.349452   \n",
       "11557             0.818  0.656657  0.538702   1.0     0.039278  0.446969   \n",
       "42812             0.860  0.090691  0.725260   1.0     0.037526  0.422592   \n",
       "26106             0.000  0.359359  0.840252   1.0     0.057629  0.549159   \n",
       "\n",
       "       valence release_date                    artist  year  \n",
       "27694   0.3600   2016-10-28          Donald Shoenberg  2016  \n",
       "50854   0.4900         1985                    Eagles  1985  \n",
       "11557   0.0376         1948           Igor Stravinsky  1948  \n",
       "42812   0.0366         2014  William Elliott Whitmore  2014  \n",
       "26106   0.1780   2013-11-07             ‡πÄ‡∏ö‡∏ô‡∏ã‡πå-‡∏û‡∏£‡∏¥‡∏Å‡πÑ‡∏ó‡∏¢  2013  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_year.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### artist\n",
    "\n",
    "How could we use the `artist` column? There are too many artists to one hot encode it.  \n",
    "We could instead create an `artist_popularity` feature containing the mean popularity of an artist, computed as the mean popularity of all tracks the artist released _on the train set_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process artist popularity from the Training set\n",
    "\n",
    "**üìù Compute and store the `artist_popularity` as a new pandas `Series`**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_popularity = train_set[['artist', 'popularity']].groupby(['artist']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the artist popularity to `X_train_year`\n",
    "\n",
    "**üìù Create a new DataFrame `X_train_engineered` which adds a new column to the existing `X_train_year` with the `artist_popularity` corresponding to the song's artist.** \n",
    "\n",
    "üö® Make sure that the target `popularity` does not end up in `X_train_engineered` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_engineered = X_train_year.copy()\n",
    "X_train_engineered = X_train_engineered.join(artist_popularity, on='artist')\n",
    "X_train_engineered.rename(columns={'popularity': 'artist_popularity'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the artist popularity to `X_test_year`\n",
    "\n",
    "**üìù Similarily, create a new DataFrame `X_test_engineered` which also adds a new column to the existing `X_test_year` with the `artist_popularity` corresponding to the song's artist, computed from the training set.**\n",
    "\n",
    "üö®**If an artist has never been seen in the training set, use the global mean popularity of all the tracks of `X_train`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.concat([X_test, y_test], axis=1)\n",
    "artist_popularity_test = test_set[['artist', 'popularity']].groupby(['artist']).mean()\n",
    "\n",
    "X_test_engineered = X_test_year.copy()\n",
    "X_test_engineered = X_test_engineered.join(artist_popularity_test, on='artist')\n",
    "X_test_engineered.rename(columns={'popularity': 'artist_popularity'}, inplace=True)\n",
    "\n",
    "# fill null values with global mean popularity in X_train\n",
    "X_test_engineered['artist_popularity'] = X_test_engineered['artist_popularity'].fillna(X_train_engineered.artist_popularity.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your results\n",
    "\n",
    "Run the following cell to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "_ = pd.concat([X_train_engineered, X_test_engineered])\n",
    "\n",
    "ChallengeResult(\"c7_feature_engineering\",\n",
    "    shape = _.shape,\n",
    "    cols = _.columns,\n",
    "    years = _.get(\"year\"),\n",
    "    popularities = _.get(\"artist_popularity\"),\n",
    ").write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n",
    "\n",
    "**üìù Let's see how these features impact the performance of our model. Retrain the same baseline model on numerical values only, but adding the new features `year` and `artist_popularity`, and see how the performance is impacted. Save the performance in a `float` variable named `score_engineered`**\n",
    "\n",
    "üëâ Do not fine tune the model yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['acousticness', 'danceability', 'duration_ms', 'energy', 'explicit',\n",
       "       'instrumentalness', 'liveness', 'loudness', 'mode', 'speechiness',\n",
       "       'tempo', 'valence', 'release_date', 'artist', 'year',\n",
       "       'artist_popularity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_engineered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_baseline = X_train_engineered[['acousticness', \n",
    "                   'danceability', \n",
    "                   'duration_ms', \n",
    "                   'energy', \n",
    "                   'explicit', \n",
    "                   'instrumentalness', \n",
    "                   'liveness', \n",
    "                   'loudness',\n",
    "                   'mode',\n",
    "                   'speechiness',\n",
    "                   'tempo',\n",
    "                   'valence',\n",
    "                   'year',\n",
    "                   'artist_popularity',\n",
    "                  ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_eng = DummyRegressor(strategy=\"median\")\n",
    "cv_results = cross_validate(baseline_model_eng, X_train_baseline, y_train, cv=5, scoring=scoring)\n",
    "score_engineered = cv_results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-480.69396930239725"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_engineered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your results\n",
    "\n",
    "Run the following cell to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "ChallengeResult(\n",
    "    \"c7_score_engineering\",\n",
    "    scoring=scoring,\n",
    "    score_engineered=score_engineered).write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelining\n",
    "\n",
    "**üìù Let's create a full sklearn preprocessing pipeline called `preproc`. It should integrate our feature engineering for `year` and `artist_popularity`, as well as any other preprocessing of your choice**\n",
    "\n",
    "**Store also the number of columns/feature after preprocessing your inputs in a variable `col_number`**\n",
    "\n",
    "**üö®‚ö†Ô∏è Advice: SKIP the `ArtistPopularityTransformer` if you don't have time to do it. It is better for you to have a working pipeline rather than NO pipeline at all**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# üëâ Do not hesitate to reload clean new dataset if you need a fresh start\n",
    "y = data.popularity\n",
    "X = data.drop(\"popularity\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to visualize your pipeline as you build it\n",
    "from sklearn import set_config; set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ArtistPopularityTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        process artist mean popularity from artists songs popularity\n",
    "        process song global mean popularity\n",
    "        \"\"\"\n",
    "\n",
    "        # process artist popularity\n",
    "        self.artist_popularity = pd.concat([X, y],\n",
    "                               axis=1,\n",
    "                               join='inner').groupby(by='artist').mean()['popularity']\n",
    "        # process mean popularity\n",
    "        self.mean_train_popularity = y.mean()\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        apply artist mean popularity vs song global mean popularity to songs\n",
    "        \"\"\"\n",
    "        \n",
    "        # inject artist popularity\n",
    "        X_copy = X.join(self.artist_popularity, on='artist')\\\n",
    "                    .rename(columns={\"popularity\": \"artist_popularity\"})\\\n",
    "                    .drop(columns='artist')\n",
    "        \n",
    "        # fills popularity of unknown artists with song global mean popularity\n",
    "        X_copy['artist_popularity'].fillna(self.mean_train_popularity, inplace=True)\n",
    "\n",
    "        return X_copy # TODO return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YearTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Transform the release_dat in year (int)\n",
    "        \"\"\"\n",
    "        X['year'] = X['release_date'].map(lambda x: x[:4]).astype(int)\n",
    "        X_copy = X.drop(columns='release_date')\n",
    "        return X_copy # TODO return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = make_column_transformer(\n",
    "            (MinMaxScaler(), ['acousticness', 'danceability', 'duration_ms', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo','valence']),\n",
    "            (ArtistPopularityTransformer(),['artist']),\n",
    "            (YearTransformer(),['release_date']), remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_number = len(list(pd.DataFrame(preproc.fit_transform(X,y)).columns))\n",
    "col_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save your results\n",
    "\n",
    "Run the following cell to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"9c0b6e35-864e-468e-b39d-3f820c27cb11\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"9c0b6e35-864e-468e-b39d-3f820c27cb11\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('minmaxscaler', MinMaxScaler(),\n",
       "                                 ['acousticness', 'danceability', 'duration_ms',\n",
       "                                  'energy', 'instrumentalness', 'liveness',\n",
       "                                  'loudness', 'speechiness', 'tempo',\n",
       "                                  'valence']),\n",
       "                                ('artistpopularitytransformer',\n",
       "                                 ArtistPopularityTransformer(), ['artist']),\n",
       "                                ('yeartransformer', YearTransformer(),\n",
       "                                 ['release_date'])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"3366e2bd-0134-4251-903b-4ca940061d7f\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"3366e2bd-0134-4251-903b-4ca940061d7f\">minmaxscaler</label><div class=\"sk-toggleable__content\"><pre>['acousticness', 'danceability', 'duration_ms', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"dde85dc5-d071-450d-9d00-842bc6bee537\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"dde85dc5-d071-450d-9d00-842bc6bee537\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"beaed8fb-be99-4a74-9c0a-00fe86fad6ab\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"beaed8fb-be99-4a74-9c0a-00fe86fad6ab\">artistpopularitytransformer</label><div class=\"sk-toggleable__content\"><pre>['artist']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"26afd7da-faf7-44e5-a79d-03bec7ba0acd\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"26afd7da-faf7-44e5-a79d-03bec7ba0acd\">ArtistPopularityTransformer</label><div class=\"sk-toggleable__content\"><pre>ArtistPopularityTransformer()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e37bc367-75be-4986-b440-4b24be88bdbf\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"e37bc367-75be-4986-b440-4b24be88bdbf\">yeartransformer</label><div class=\"sk-toggleable__content\"><pre>['release_date']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"4c0844e7-8d3e-4027-b4d2-256e5b1e5d7c\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"4c0844e7-8d3e-4027-b4d2-256e5b1e5d7c\">YearTransformer</label><div class=\"sk-toggleable__content\"><pre>YearTransformer()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c11b6700-6070-4ef3-9328-825d752010ca\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"c11b6700-6070-4ef3-9328-825d752010ca\">remainder</label><div class=\"sk-toggleable__content\"><pre>['explicit', 'id', 'key', 'mode', 'name']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5fbb2128-5eb4-4f40-aed0-13c603c04e5b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5fbb2128-5eb4-4f40-aed0-13c603c04e5b\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('minmaxscaler', MinMaxScaler(),\n",
       "                                 ['acousticness', 'danceability', 'duration_ms',\n",
       "                                  'energy', 'instrumentalness', 'liveness',\n",
       "                                  'loudness', 'speechiness', 'tempo',\n",
       "                                  'valence']),\n",
       "                                ('artistpopularitytransformer',\n",
       "                                 ArtistPopularityTransformer(), ['artist']),\n",
       "                                ('yeartransformer', YearTransformer(),\n",
       "                                 ['release_date'])])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print below your preproc here for the correctors\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "ChallengeResult(\n",
    "    \"c6_preprocessing\",\n",
    "    col_number=col_number\n",
    ").write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "üìù Time to optimize \n",
    "\n",
    "- **Add an estimator to your pipeline (only from scikit-learn)** \n",
    "\n",
    "- **Train your pipeline and fine-tune (optimize) your estimator to get the best prediction score**\n",
    "\n",
    "- **You must create 2 pipelines (one with a linear model, one with an ensemble model)**\n",
    "\n",
    "Then, \n",
    "\n",
    "- Save your two best 5-time cross-validated scores as _float_: `score_linear` and `score_ensemble`\n",
    "\n",
    "- Save your two best trained pipelines as _Pipeline_ objects: `pipe_linear` and `pipe_ensemble`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your results\n",
    "\n",
    "Run the following cell to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print below your best pipe for correction purpose\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "pipe_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print below your best pipe for correction purpose\n",
    "pipe_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "ChallengeResult(\"c8_c9_c11_c13_model_tuning\",\n",
    "    scoring = scoring,\n",
    "    score_linear=score_linear,\n",
    "    score_ensemble=score_ensemble).write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API \n",
    "\n",
    "Time to put a pipeline in production!\n",
    "\n",
    "üëâ Go to https://github.com/lewagon/data-certification-api and follow instructions\n",
    "\n",
    "**This final part is independent from the above notebook**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "252.003px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
