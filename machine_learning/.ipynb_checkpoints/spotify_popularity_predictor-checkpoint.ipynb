{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Popularity Predictor (39%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this challenge is to create a model that predicts the popularity of a song based on its features.\n",
    "\n",
    "The dataset contains a list of tracks with the following characteristics:\n",
    "- `acousticness`: whether the track is acoustic\n",
    "- `danceability`: describes how suitable a track is for dancing\n",
    "- `duration_ms`: duration of the track in milliseconds\n",
    "- `energy`: represents a perceptual measure of intensity and activity\n",
    "- `explicit`: whether the track has explicit lyrics\n",
    "- `id`: id for the track\n",
    "- `instrumentalness`: predicts whether a track contains no vocals\n",
    "- `key`: the key the track is in\n",
    "- `liveness`: detects the presence of an audience in the recording\n",
    "- `loudness`: the overall loudness of a track in decibels\n",
    "- `mode`: modality of a track\n",
    "- `name`: name of the track\n",
    "- `popularity`: popularity of the track\n",
    "- `release_date`: release date\n",
    "- `speechiness`: detects the presence of spoken words in a track\n",
    "- `tempo`: overall estimated tempo of a track in beats per minute\n",
    "- `valence`: describes the musical positiveness conveyed by a track\n",
    "- `artist`: artist who performed the track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection\n",
    "\n",
    "**üìù Load the `spotify_popularity_train.csv` dataset from the provided URL. Display the first few rows. Perform the usual cleaning operations. Store the result in a `DataFrame` named `data`.**\n",
    "\n",
    "üëâ Do not forget to clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://wagon-public-datasets.s3.amazonaws.com/certification_paris_2021Q1/spotify_popularity_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>id</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.65400</td>\n",
       "      <td>0.499</td>\n",
       "      <td>219827</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0</td>\n",
       "      <td>0B6BeEUd6UwFlbsHMQKjob</td>\n",
       "      <td>0.00409</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>-16.435</td>\n",
       "      <td>1</td>\n",
       "      <td>Back in the Goodle Days</td>\n",
       "      <td>40</td>\n",
       "      <td>1971</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>149.460</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>John Hartford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00592</td>\n",
       "      <td>0.439</td>\n",
       "      <td>483948</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0</td>\n",
       "      <td>5Gpx4lJy3vKmIvjwbiR5c8</td>\n",
       "      <td>0.14000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>-8.497</td>\n",
       "      <td>1</td>\n",
       "      <td>Worlds Which Break Us - Intro Mix</td>\n",
       "      <td>22</td>\n",
       "      <td>2015-02-02</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>138.040</td>\n",
       "      <td>0.0587</td>\n",
       "      <td>Driftmoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.73400</td>\n",
       "      <td>0.523</td>\n",
       "      <td>245693</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0</td>\n",
       "      <td>7MxuUYqrCIy93h1EEHrIrL</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>-11.506</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm The Greatest Star</td>\n",
       "      <td>40</td>\n",
       "      <td>1968-09-01</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>75.869</td>\n",
       "      <td>0.4640</td>\n",
       "      <td>Barbra Streisand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms  energy  explicit  \\\n",
       "0       0.65400         0.499       219827   0.190         0   \n",
       "1       0.00592         0.439       483948   0.808         0   \n",
       "2       0.73400         0.523       245693   0.288         0   \n",
       "\n",
       "                       id  instrumentalness  key  liveness  loudness  mode  \\\n",
       "0  0B6BeEUd6UwFlbsHMQKjob           0.00409    7    0.0898   -16.435     1   \n",
       "1  5Gpx4lJy3vKmIvjwbiR5c8           0.14000    2    0.0890    -8.497     1   \n",
       "2  7MxuUYqrCIy93h1EEHrIrL           0.00000    0    0.0771   -11.506     1   \n",
       "\n",
       "                                name  popularity release_date  speechiness  \\\n",
       "0            Back in the Goodle Days          40         1971       0.0454   \n",
       "1  Worlds Which Break Us - Intro Mix          22   2015-02-02       0.0677   \n",
       "2              I'm The Greatest Star          40   1968-09-01       0.2140   \n",
       "\n",
       "     tempo  valence            artist  \n",
       "0  149.460   0.4300     John Hartford  \n",
       "1  138.040   0.0587         Driftmoon  \n",
       "2   75.869   0.4640  Barbra Streisand  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(url)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52317 entries, 0 to 52316\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   acousticness      52317 non-null  float64\n",
      " 1   danceability      52317 non-null  float64\n",
      " 2   duration_ms       52317 non-null  int64  \n",
      " 3   energy            52317 non-null  float64\n",
      " 4   explicit          52317 non-null  int64  \n",
      " 5   id                52317 non-null  object \n",
      " 6   instrumentalness  52317 non-null  float64\n",
      " 7   key               52317 non-null  int64  \n",
      " 8   liveness          52317 non-null  float64\n",
      " 9   loudness          52317 non-null  float64\n",
      " 10  mode              52317 non-null  int64  \n",
      " 11  name              52317 non-null  object \n",
      " 12  popularity        52317 non-null  int64  \n",
      " 13  release_date      52317 non-null  object \n",
      " 14  speechiness       52317 non-null  float64\n",
      " 15  tempo             52317 non-null  float64\n",
      " 16  valence           52317 non-null  float64\n",
      " 17  artist            52313 non-null  object \n",
      "dtypes: float64(9), int64(5), object(4)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates, drop null values\n",
    "data = data.drop_duplicates().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale values\n",
    "scaler = MinMaxScaler()\n",
    "features_to_scale = ['acousticness', \n",
    "                   'danceability', \n",
    "                   'duration_ms',\n",
    "                   'energy', \n",
    "                   'explicit', \n",
    "                   'instrumentalness', \n",
    "                   'liveness', \n",
    "                   'loudness',\n",
    "                   'mode',\n",
    "                   'speechiness',\n",
    "                   'tempo',\n",
    "                   'valence'\n",
    "                  ]\n",
    "data[features_to_scale] = scaler.fit_transform(data[features_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your results\n",
    "\n",
    "Run the following cell to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "ChallengeResult(\n",
    "    \"c5_data_cleaning\",\n",
    "    data=data).write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù We want to use a metric that measures the prediction error in the same unit than `popularity`. In addition, it should strongly penalize largest errors. Which sklearn's [metric](https://scikit-learn.org/stable/modules/model_evaluation.html) should we use? Store its exact name as string below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = \"neg_mean_squared_error\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Let's build a baseline model using only the numerical features in our dataset.**\n",
    "- Build `X_baseline` with only numerical features\n",
    "- Build `y` your target containing the `popularity`\n",
    "- Then 5 times cross validate the baseline linear model of your choice (do not fine tune it)\n",
    "- Store your mean performance in a `float` variable named `baseline_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_baseline = data[['acousticness', \n",
    "                   'danceability', \n",
    "                   'duration_ms', \n",
    "                   'energy', \n",
    "                   'explicit', \n",
    "                   'instrumentalness', \n",
    "                   'liveness', \n",
    "                   'loudness',\n",
    "                   'mode',\n",
    "                   'speechiness',\n",
    "                   'tempo',\n",
    "                   'valence'\n",
    "                  ]]\n",
    "\n",
    "y = data['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = DummyRegressor(strategy=\"median\")\n",
    "cv_results = cross_validate(baseline_model, X_baseline, y, cv=5, scoring=scoring)\n",
    "baseline_score = cv_results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your results\n",
    "\n",
    "Run the following cell to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "ChallengeResult(\n",
    "    \"baseline\",\n",
    "    scoring=scoring,\n",
    "    baseline_score=baseline_score).write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "Let's now use the features that we left aside: `release_date` and `artist` to improve the performance of our model. We'll create them manually in a train vs. test context first (and pipeline them later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### holdout\n",
    "**üìù Create the 4 variables `X_train` `y_train`, `X_test`, `y_test` with a 50% split with random sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['acousticness', \n",
    "                   'danceability', \n",
    "                   'duration_ms', \n",
    "                   'energy', \n",
    "                   'explicit', \n",
    "                   'instrumentalness', \n",
    "                   'liveness', \n",
    "                   'loudness',\n",
    "                   'mode',\n",
    "                   'speechiness',\n",
    "                   'tempo',\n",
    "                   'valence',\n",
    "                   'release_date',\n",
    "                   'artist',\n",
    "                  ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### year\n",
    "\n",
    "**üìù Create `X_train_year` and `X_test_year` by adding the new column `year` containing the release year of the track as integer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### artist\n",
    "\n",
    "How could we use the `artist` column? There are too many artists to one hot encode it.  \n",
    "We could instead create an `artist_popularity` feature containing the mean popularity of an artist, computed as the mean popularity of all tracks the artist released _on the train set_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process artist popularity from the Training set\n",
    "\n",
    "**üìù Compute and store the `artist_popularity` as a new pandas `Series`**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the artist popularity to `X_train_year`\n",
    "\n",
    "**üìù Create a new DataFrame `X_train_engineered` which adds a new column to the existing `X_train_year` with the `artist_popularity` corresponding to the song's artist.** \n",
    "\n",
    "üö® Make sure that the target `popularity` does not end up in `X_train_engineered` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the artist popularity to `X_test_year`\n",
    "\n",
    "**üìù Similarily, create a new DataFrame `X_test_engineered` which also adds a new column to the existing `X_test_year` with the `artist_popularity` corresponding to the song's artist, computed from the training set.**\n",
    "\n",
    "üö®**If an artist has never been seen in the training set, use the global mean popularity of all the tracks of `X_train`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your results\n",
    "\n",
    "Run the following cell to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "_ = pd.concat([X_train_engineered, X_test_engineered])\n",
    "\n",
    "ChallengeResult(\"c7_feature_engineering\",\n",
    "    shape = _.shape,\n",
    "    cols = _.columns,\n",
    "    years = _.get(\"year\"),\n",
    "    popularities = _.get(\"artist_popularity\"),\n",
    ").write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n",
    "\n",
    "**üìù Let's see how these features impact the performance of our model. Retrain the same baseline model on numerical values only, but adding the new features `year` and `artist_popularity`, and see how the performance is impacted. Save the performance in a `float` variable named `score_engineered`**\n",
    "\n",
    "üëâ Do not fine tune the model yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your results\n",
    "\n",
    "Run the following cell to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "ChallengeResult(\n",
    "    \"c7_score_engineering\",\n",
    "    scoring=scoring,\n",
    "    score_engineered=score_engineered).write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelining\n",
    "\n",
    "**üìù Let's create a full sklearn preprocessing pipeline called `preproc`. It should integrate our feature engineering for `year` and `artist_popularity`, as well as any other preprocessing of your choice**\n",
    "\n",
    "**Store also the number of columns/feature after preprocessing your inputs in a variable `col_number`**\n",
    "\n",
    "**üö®‚ö†Ô∏è Advice: SKIP the `ArtistPopularityTransformer` if you don't have time to do it. It is better for you to have a working pipeline rather than NO pipeline at all**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# üëâ Do not hesitate to reload clean new dataset if you need a fresh start\n",
    "y = data.popularity\n",
    "X = data.drop(\"popularity\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to visualize your pipeline as you build it\n",
    "from sklearn import set_config; set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We give you below the skeleton of the custom ArtistPopularityTransformer to complete\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ArtistPopularityTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        process artist mean popularity from artists songs popularity\n",
    "        process song global mean popularity\n",
    "        \"\"\"\n",
    "\n",
    "        # process artist popularity\n",
    "\n",
    "        # process mean popularity\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        apply artist mean popularity vs song global mean popularity to songs\n",
    "        \"\"\"\n",
    "\n",
    "        # inject artist popularity\n",
    "\n",
    "        # fills popularity of unknown artists with song global mean popularity\n",
    "\n",
    "        return # TODO return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save your results\n",
    "\n",
    "Run the following cell to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print below your preproc here for the correctors\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "ChallengeResult(\n",
    "    \"c6_preprocessing\",\n",
    "    col_number=col_number\n",
    ").write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "üìù Time to optimize \n",
    "\n",
    "- **Add an estimator to your pipeline (only from scikit-learn)** \n",
    "\n",
    "- **Train your pipeline and fine-tune (optimize) your estimator to get the best prediction score**\n",
    "\n",
    "- **You must create 2 pipelines (one with a linear model, one with an ensemble model)**\n",
    "\n",
    "Then, \n",
    "\n",
    "- Save your two best 5-time cross-validated scores as _float_: `score_linear` and `score_ensemble`\n",
    "\n",
    "- Save your two best trained pipelines as _Pipeline_ objects: `pipe_linear` and `pipe_ensemble`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your results\n",
    "\n",
    "Run the following cell to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print below your best pipe for correction purpose\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "pipe_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print below your best pipe for correction purpose\n",
    "pipe_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "ChallengeResult(\"c8_c9_c11_c13_model_tuning\",\n",
    "    scoring = scoring,\n",
    "    score_linear=score_linear,\n",
    "    score_ensemble=score_ensemble).write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API \n",
    "\n",
    "Time to put a pipeline in production!\n",
    "\n",
    "üëâ Go to https://github.com/lewagon/data-certification-api and follow instructions\n",
    "\n",
    "**This final part is independent from the above notebook**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "252.003px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
